{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt.rcdefaults()\n",
    "mpl.style.use('additional')\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss\n",
    "from scipy import sparse\n",
    "from xgboost import XGBClassifier\n",
    "from pylightgbm.models import GBMClassifier\n",
    "os.environ['LIGHTGBM_EXEC'] = '/Users/Terence/Develop/bin/lightgbm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    fmt = lambda s: s.replace(\"\\u00a0\", \"\").strip().lower()\n",
    "    df[\"photo_count\"] = df[\"photos\"].apply(len)\n",
    "    df[\"street_address\"] = df['street_address'].apply(fmt)\n",
    "    df[\"display_address\"] = df[\"display_address\"].apply(fmt)\n",
    "    df[\"desc_wordcount\"] = df[\"description\"].apply(str.split).apply(len)\n",
    "    df[\"pricePerBed\"] = df['price'] / df['bedrooms']\n",
    "    df[\"pricePerBath\"] = df['price'] / df['bathrooms']\n",
    "    df[\"pricePerRoom\"] = df['price'] / (df['bedrooms'] + df['bathrooms'])\n",
    "    df[\"bedPerBath\"] = df['bedrooms'] / df['bathrooms']\n",
    "    df[\"bedBathDiff\"] = df['bedrooms'] - df['bathrooms']\n",
    "    df[\"bedBathSum\"] = df[\"bedrooms\"] + df['bathrooms']\n",
    "    df[\"bedsPerc\"] = df[\"bedrooms\"] / (df['bedrooms'] + df['bathrooms'])\n",
    "\n",
    "    df = df.fillna(-1).replace(np.inf, -1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def factorize(df1, df2, column):\n",
    "    ps = df1[column].append(df2[column])\n",
    "    factors = ps.factorize()[0]\n",
    "    df1[column] = factors[:len(df1)]\n",
    "    df2[column] = factors[len(df1):]\n",
    "    return df1, df2\n",
    "\n",
    "\n",
    "def designate_single_observations(df1, df2, column):\n",
    "    ps = df1[column].append(df2[column])\n",
    "    grouped = ps.groupby(ps).size().to_frame().rename(columns={0: \"size\"})\n",
    "    df1.loc[df1.join(grouped, on=column, how=\"left\")[\"size\"] <= 1, column] = -1\n",
    "    df2.loc[df2.join(grouped, on=column, how=\"left\")[\"size\"] <= 1, column] = -1\n",
    "    return df1, df2\n",
    "\n",
    "\n",
    "def hcc_encode(train_df, test_df, variable, target, prior_prob, k, f=1, g=1, r_k=None, update_df=None):\n",
    "    \"\"\"\n",
    "    See \"A Preprocessing Scheme for High-Cardinality Categorical Attributes in\n",
    "    Classification and Prediction Problems\" by Daniele Micci-Barreca\n",
    "    \"\"\"\n",
    "    hcc_name = \"_\".join([\"hcc\", variable, target])\n",
    "\n",
    "    grouped = train_df.groupby(variable)[target].agg({\"size\": \"size\", \"mean\": \"mean\"})\n",
    "    grouped[\"lambda\"] = 1 / (g + np.exp((k - grouped[\"size\"]) / f))\n",
    "    grouped[hcc_name] = grouped[\"lambda\"] * grouped[\"mean\"] + (1 - grouped[\"lambda\"]) * prior_prob\n",
    "\n",
    "    df = test_df[[variable]].join(grouped, on=variable, how=\"left\")[hcc_name].fillna(prior_prob)\n",
    "    if r_k: df *= np.random.uniform(1 - r_k, 1 + r_k, len(test_df))     # Add uniform noise. Not mentioned in original paper\n",
    "\n",
    "    if update_df is None: update_df = test_df\n",
    "    if hcc_name not in update_df.columns: update_df[hcc_name] = np.nan\n",
    "    update_df.update(df)\n",
    "    return\n",
    "\n",
    "\n",
    "def create_binary_features(df):\n",
    "    bows = {\n",
    "        \"dogs\": (\"dogs\", \"dog\"),\n",
    "        \"cats\": (\"cats\",),\n",
    "        \"nofee\": (\"no fee\", \"no-fee\", \"no  fee\", \"nofee\", \"no_fee\"),\n",
    "        \"lowfee\": (\"reduced_fee\", \"low_fee\", \"reduced fee\", \"low fee\"),\n",
    "        \"furnished\": (\"furnished\",),\n",
    "        \"parquet\": (\"parquet\", \"hardwood\"),\n",
    "        \"concierge\": (\"concierge\", \"doorman\", \"housekeep\", \"in_super\"),\n",
    "        \"prewar\": (\"prewar\", \"pre_war\", \"pre war\", \"pre-war\"),\n",
    "        \"laundry\": (\"laundry\", \"lndry\"),\n",
    "        \"health\": (\"health\", \"gym\", \"fitness\", \"training\"),\n",
    "        \"transport\": (\"train\", \"subway\", \"transport\"),\n",
    "        \"parking\": (\"parking\",),\n",
    "        \"utilities\": (\"utilities\", \"heat water\", \"water included\")\n",
    "    }\n",
    "\n",
    "    def indicator(bow):\n",
    "        return lambda s: int(any([x in s for x in bow]))\n",
    "\n",
    "    features = df[\"features\"].apply(lambda f: \" \".join(f).lower())   # convert features to string\n",
    "    for key in bows:\n",
    "        df[\"feature_\" + key] = features.apply(indicator(bows[key]))\n",
    "\n",
    "    return df\n",
    "    \n",
    "    \n",
    "# Load data\n",
    "X_train = pd.read_json(\"train.json\").sort_values(by=\"listing_id\")\n",
    "X_test = pd.read_json(\"test.json\").sort_values(by=\"listing_id\")\n",
    "\n",
    "# Make target integer, one hot encoded, calculate target priors\n",
    "X_train = X_train.replace({\"interest_level\": {\"low\": 0, \"medium\": 1, \"high\": 2}})\n",
    "X_train = X_train.join(pd.get_dummies(X_train[\"interest_level\"], prefix=\"pred\").astype(int))\n",
    "prior_0, prior_1, prior_2 = X_train[[\"pred_0\", \"pred_1\", \"pred_2\"]].mean()\n",
    "\n",
    "# Add common features\n",
    "X_train = add_features(X_train)\n",
    "X_test = add_features(X_test)\n",
    "\n",
    "# Special designation for building_ids, manager_ids, display_address with only 1 observation\n",
    "for col in ('building_id', 'manager_id', 'display_address'):\n",
    "    X_train, X_test = designate_single_observations(X_train, X_test, col)\n",
    "\n",
    "# High-Cardinality Categorical encoding\n",
    "skf = StratifiedKFold(5)\n",
    "attributes = product((\"building_id\", \"manager_id\"), zip((\"pred_1\", \"pred_2\"), (prior_1, prior_2)))\n",
    "for variable, (target, prior) in attributes:\n",
    "    hcc_encode(X_train, X_test, variable, target, prior, k=5, r_k=None)\n",
    "    for train, test in skf.split(np.zeros(len(X_train)), X_train['interest_level']):\n",
    "        hcc_encode(X_train.iloc[train], X_train.iloc[test], variable, target, prior, k=5, r_k=0.01, update_df=X_train)\n",
    "\n",
    "# Factorize building_id, display_address, manager_id, street_address\n",
    "for col in ('building_id', 'display_address', 'manager_id', 'street_address'):\n",
    "    X_train, X_test = factorize(X_train, X_test, col)\n",
    "\n",
    "# Create binarized features\n",
    "X_train = create_binary_features(X_train)\n",
    "X_test = create_binary_features(X_test)\n",
    "\n",
    "# save\n",
    "X_train = X_train.sort_index(axis=1).sort_index()\n",
    "X_test = X_test.sort_index(axis=1).sort_index()\n",
    "columns_to_drop = [\"photos\", \"pred_0\",\"pred_1\", \"pred_2\", \"created\"]\n",
    "X_train.drop(columns_to_drop, axis=1, errors=\"ignore\", inplace=True)\n",
    "X_test.drop(columns_to_drop, axis=1, errors=\"ignore\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def features_cleanup_star(x):\n",
    "    return list(chain.from_iterable(re.sub(r'\\s*\\*+\\s*\\**\\s*', r'*', i).strip('*').split('*') for i in x))\n",
    "\n",
    "def process_features(df):\n",
    "    df['features_clean'] = df['features']\\\n",
    "                    .apply(lambda x: ' '.join([re.sub(r'\\W', '', i) for i in x]).lower())\n",
    "\n",
    "    df.loc[df.features_clean.str.contains('\\*'), 'features_clean'] = \\\n",
    "            df.loc[df.features_clean.str.contains('\\*'), 'features']\\\n",
    "                    .apply(features_cleanup_star)\\\n",
    "                    .apply(lambda x: ' '.join([re.sub(r'\\W', '', i) for i in x]).lower())\n",
    "                \n",
    "process_features(X_train)\n",
    "process_features(X_test)\n",
    "\n",
    "countvec_features = CountVectorizer(stop_words='english', max_features=200)\n",
    "countvec_features.fit(X_train['features_clean'].tolist() + X_test['features_clean'].tolist())\n",
    "X_train_features = countvec_features.transform(X_train['features_clean'])\n",
    "X_test_features = countvec_features.transform(X_test['features_clean'])\n",
    "\n",
    "countvec_desc = CountVectorizer(stop_words='english', max_features=200)\n",
    "countvec_desc.fit(X_train['description'].tolist() + X_test['description'].tolist())\n",
    "X_train_desc = countvec_desc.transform(X_train['description'])\n",
    "X_test_desc = countvec_desc.transform(X_test['description'])\n",
    "\n",
    "columns_to_drop = [\"description\", \"features\", \"features_clean\"]\n",
    "X_train.drop(columns_to_drop, axis=1, errors=\"ignore\", inplace=True)\n",
    "X_test.drop(columns_to_drop, axis=1, errors=\"ignore\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bathrooms', 'bedBathDiff', 'bedBathSum', 'bedPerBath', 'bedrooms',\n",
       "       'bedsPerc', 'building_id', 'desc_wordcount', 'display_address',\n",
       "       'feature_cats', 'feature_concierge', 'feature_dogs',\n",
       "       'feature_furnished', 'feature_health', 'feature_laundry',\n",
       "       'feature_lowfee', 'feature_nofee', 'feature_parking', 'feature_parquet',\n",
       "       'feature_prewar', 'feature_transport', 'feature_utilities',\n",
       "       'hcc_building_id_pred_1', 'hcc_building_id_pred_2',\n",
       "       'hcc_manager_id_pred_1', 'hcc_manager_id_pred_2', 'interest_level',\n",
       "       'latitude', 'listing_id', 'longitude', 'manager_id', 'photo_count',\n",
       "       'price', 'pricePerBath', 'pricePerBed', 'pricePerRoom',\n",
       "       'street_address'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `XGBClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5550611 , -0.55131487, -0.54869598])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = XGBClassifier(max_depth=10, learning_rate=0.1, n_estimators=100, objective='multi:softprob', subsample=0.7)\\\n",
    "                .fit(X_train.drop('interest_level', axis=1), X_train.interest_level)\n",
    "scores = cross_val_score(gbc, X_train.drop('interest_level', axis=1), X_train.interest_level, scoring='neg_log_loss', \n",
    "                         cv=StratifiedKFold(3, shuffle=True), n_jobs=-1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `LightGBM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/base.py:122: DeprecationWarning: Estimator GBMClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/base.py:122: DeprecationWarning: Estimator GBMClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/base.py:122: DeprecationWarning: Estimator GBMClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.54471735, -0.55575272, -0.5539737 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbgm = GBMClassifier(application='multiclass', metric='multi_logloss', learning_rate=0.1, num_iterations=100, num_class=3, early_stopping_round=10, verbose=False)\n",
    "lbgm.fit(X_train.drop('interest_level', axis=1), X_train.interest_level)\n",
    "scores = cross_val_score(lbgm, X_train.drop('interest_level', axis=1), X_train.interest_level, scoring='neg_log_loss', \n",
    "                         cv=StratifiedKFold(3, shuffle=True), n_jobs=-1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include the text probs from `SGD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_text_combined = sparse.hstack([X_train_features, X_train_desc]).tocsr()\n",
    "sgd = SGDClassifier(alpha=1e-3, n_jobs=-1, loss='log').fit(X_train_text_combined, X_train.interest_level)\n",
    "y_pred_cv_sgd = cross_val_predict(sgd, X_train_text_combined, X_train.interest_level, n_jobs=-1, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5561396 , -0.55336424, -0.56136587])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_semi = XGBClassifier(max_depth=10, learning_rate=0.1, n_estimators=100, objective='multi:softprob', subsample=0.7)\\\n",
    "                .fit(np.hstack([X_train.drop('interest_level', axis=1), y_pred_cv_sgd]), X_train.interest_level)\n",
    "scores = cross_val_score(gbc_semi, np.hstack([X_train.drop('interest_level', axis=1), y_pred_cv_sgd]), X_train.interest_level, scoring='neg_log_loss', \n",
    "                         cv=StratifiedKFold(3, shuffle=True), n_jobs=-1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `LightGBM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/base.py:122: DeprecationWarning: Estimator GBMClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/base.py:122: DeprecationWarning: Estimator GBMClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/base.py:122: DeprecationWarning: Estimator GBMClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.5587934 , -0.55233137, -0.54761985])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbgm_semi = GBMClassifier(application='multiclass', metric='multi_logloss', learning_rate=0.1, num_iterations=100, num_class=3, early_stopping_round=10, verbose=False)\n",
    "lbgm_semi.fit(np.hstack([X_train.drop('interest_level', axis=1), y_pred_cv_sgd]), X_train.interest_level)\n",
    "scores = cross_val_score(lbgm_semi, np.hstack([X_train.drop('interest_level', axis=1), y_pred_cv_sgd]), X_train.interest_level, scoring='neg_log_loss', \n",
    "                         cv=StratifiedKFold(3, shuffle=True), n_jobs=-1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_text_combined = sparse.hstack([X_test_features, X_test_desc]).tocsr()\n",
    "y_test_pred_sgd = sgd.predict_proba(X_test_text_combined)\n",
    "y_test = lbgm.predict_proba(np.hstack([X_test, y_test_pred_sgd]))\n",
    "# pd.DataFrame(y_test, index=X_test.listing_id, columns=['low', 'medium', 'high'])[['high', 'medium', 'low']].to_csv('submission_xgb_more_features-lbgm.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
